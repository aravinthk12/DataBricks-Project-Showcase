{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f971e10f-4b6a-41a0-9579-0453c24744e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nProcessing /Workspace/Users/arvindk2505@outlook.com/.bundle/HousePricePredictor/dev/artifacts/.internal/showcase-0.1.0-py3-none-any.whl\nCollecting pyspark<4.0.0,>=3.5.2\n  Using cached pyspark-3.5.2-py2.py3-none-any.whl\nCollecting pandas<3.0.0,>=2.2.2\n  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\nCollecting hydra-core<2.0.0,>=1.3.2\n  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\nCollecting black<25.0.0,>=24.8.0\n  Using cached black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\nCollecting mlflow<3.0.0,>=2.16.0\n  Using cached mlflow-2.16.1-py3-none-any.whl (26.7 MB)\nRequirement already satisfied: tomli>=1.1.0 in /databricks/python3/lib/python3.10/site-packages (from black<25.0.0,>=24.8.0->showcase==0.1.0) (2.0.1)\nRequirement already satisfied: packaging>=22.0 in /databricks/python3/lib/python3.10/site-packages (from black<25.0.0,>=24.8.0->showcase==0.1.0) (23.2)\nRequirement already satisfied: click>=8.0.0 in /databricks/python3/lib/python3.10/site-packages (from black<25.0.0,>=24.8.0->showcase==0.1.0) (8.0.4)\nRequirement already satisfied: typing-extensions>=4.0.1 in /databricks/python3/lib/python3.10/site-packages (from black<25.0.0,>=24.8.0->showcase==0.1.0) (4.4.0)\nRequirement already satisfied: pathspec>=0.9.0 in /databricks/python3/lib/python3.10/site-packages (from black<25.0.0,>=24.8.0->showcase==0.1.0) (0.10.3)\nRequirement already satisfied: platformdirs>=2 in /databricks/python3/lib/python3.10/site-packages (from black<25.0.0,>=24.8.0->showcase==0.1.0) (2.5.2)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /databricks/python3/lib/python3.10/site-packages (from black<25.0.0,>=24.8.0->showcase==0.1.0) (0.4.3)\nCollecting omegaconf<2.4,>=2.2\n  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\nCollecting antlr4-python3-runtime==4.9.*\n  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\nCollecting sqlalchemy<3,>=1.4.0\n  Using cached SQLAlchemy-2.0.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.1.1)\nCollecting alembic!=1.10.0,<2\n  Using cached alembic-1.13.2-py3-none-any.whl (232 kB)\nCollecting gunicorn<24\n  Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.10/site-packages (from mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.10.0)\nCollecting mlflow-skinny==2.16.1\n  Using cached mlflow_skinny-2.16.1-py3-none-any.whl (5.6 MB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.10/site-packages (from mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (3.7.0)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.10/site-packages (from mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.23.5)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.10/site-packages (from mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (3.1.2)\nCollecting docker<8,>=4.0.0\n  Using cached docker-7.1.0-py3-none-any.whl (147 kB)\nCollecting markdown<4,>=3.3\n  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\nCollecting graphene<4\n  Using cached graphene-3.3-py2.py3-none-any.whl (128 kB)\nRequirement already satisfied: pyarrow<18,>=4.0.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (8.0.0)\nCollecting Flask<4\n  Using cached flask-3.0.3-py3-none-any.whl (101 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0\n  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\nRequirement already satisfied: protobuf<6,>=3.12.0 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.16.1->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (4.24.0)\nCollecting gitpython<4,>=3.1.9\n  Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\nCollecting cachetools<6,>=5.0.0\n  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\nCollecting databricks-sdk<1,>=0.20.0\n  Using cached databricks_sdk-0.32.1-py3-none-any.whl (551 kB)\nCollecting cloudpickle<4\n  Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\nCollecting sqlparse<1,>=0.4.0\n  Using cached sqlparse-0.5.1-py3-none-any.whl (44 kB)\nRequirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/lib/python3/dist-packages (from mlflow-skinny==2.16.1->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (4.6.4)\nCollecting opentelemetry-api<3,>=1.9.0\n  Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\nCollecting pyyaml<7,>=5.1\n  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.10/site-packages (from mlflow-skinny==2.16.1->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (2.28.1)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas<3.0.0,>=2.2.2->showcase==0.1.0) (2022.7)\nCollecting tzdata>=2022.7\n  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.10/site-packages (from pandas<3.0.0,>=2.2.2->showcase==0.1.0) (2.8.2)\nCollecting py4j==0.10.9.7\n  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\nCollecting Mako\n  Using cached Mako-1.3.5-py3-none-any.whl (78 kB)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.26.14)\nCollecting itsdangerous>=2.1.2\n  Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nCollecting click>=8.0.0\n  Using cached click-8.1.7-py3-none-any.whl (97 kB)\nCollecting Werkzeug>=3.0.0\n  Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\nCollecting blinker>=1.6.2\n  Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\nCollecting graphql-relay<3.3,>=3.1\n  Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nCollecting aniso8601<10,>=8\n  Using cached aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\nCollecting graphql-core<3.3,>=3.1\n  Using cached graphql_core-3.2.4-py3-none-any.whl (203 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (2.1.1)\nRequirement already satisfied: contourpy>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.0.5)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (4.25.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (3.0.9)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.10/site-packages (from matplotlib<4->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (9.4.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.2->showcase==0.1.0) (1.16.0)\nRequirement already satisfied: joblib>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.10/site-packages (from scikit-learn<2->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (2.2.0)\nCollecting typing-extensions>=4.0.1\n  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nCollecting greenlet!=0.4.17\n  Using cached greenlet-3.1.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (617 kB)\nCollecting google-auth~=2.0\n  Using cached google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\nCollecting gitdb<5,>=4.0.1\n  Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\nCollecting deprecated>=1.2.6\n  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\nCollecting importlib-metadata!=4.7.0,<9,>=3.7.0\n  Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\nRequirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.16.1->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (1.0.0)\nCollecting opentelemetry-semantic-conventions==0.48b0\n  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.1->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.1->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.16.1->mlflow<3.0.0,>=2.16.0->showcase==0.1.0) (3.4)\nCollecting wrapt<2,>=1.10\n  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\nCollecting smmap<6,>=3.0.1\n  Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\nCollecting pyasn1-modules>=0.2.1\n  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\nCollecting rsa<5,>=3.1.4\n  Using cached rsa-4.9-py3-none-any.whl (34 kB)\nCollecting pyasn1<0.7.0,>=0.4.6\n  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\nInstalling collected packages: py4j, antlr4-python3-runtime, aniso8601, wrapt, Werkzeug, tzdata, typing-extensions, sqlparse, smmap, pyyaml, pyspark, pyasn1, markdown, Mako, itsdangerous, importlib-metadata, gunicorn, greenlet, graphql-core, cloudpickle, click, cachetools, blinker, sqlalchemy, rsa, pyasn1-modules, pandas, omegaconf, graphql-relay, gitdb, Flask, docker, deprecated, black, opentelemetry-api, hydra-core, graphene, google-auth, gitpython, alembic, opentelemetry-semantic-conventions, databricks-sdk, opentelemetry-sdk, mlflow-skinny, mlflow, showcase\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.4.0\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f7a49a5e-f446-4cd2-93d1-38f336fc1750\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.6.4\n    Not uninstalling importlib-metadata at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f7a49a5e-f446-4cd2-93d1-38f336fc1750\n    Can't uninstall 'importlib-metadata'. No files were found to uninstall.\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f7a49a5e-f446-4cd2-93d1-38f336fc1750\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: blinker\n    Found existing installation: blinker 1.4\n    Not uninstalling blinker at /usr/lib/python3/dist-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f7a49a5e-f446-4cd2-93d1-38f336fc1750\n    Can't uninstall 'blinker'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f7a49a5e-f446-4cd2-93d1-38f336fc1750\n    Can't uninstall 'pandas'. No files were found to uninstall.\n  Attempting uninstall: black\n    Found existing installation: black 22.6.0\n    Not uninstalling black at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f7a49a5e-f446-4cd2-93d1-38f336fc1750\n    Can't uninstall 'black'. No files were found to uninstall.\n  Attempting uninstall: databricks-sdk\n    Found existing installation: databricks-sdk 0.1.6\n    Not uninstalling databricks-sdk at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f7a49a5e-f446-4cd2-93d1-38f336fc1750\n    Can't uninstall 'databricks-sdk'. No files were found to uninstall.\nSuccessfully installed Flask-3.0.3 Mako-1.3.5 Werkzeug-3.0.4 alembic-1.13.2 aniso8601-9.0.1 antlr4-python3-runtime-4.9.3 black-24.8.0 blinker-1.8.2 cachetools-5.5.0 click-8.1.7 cloudpickle-3.0.0 databricks-sdk-0.32.1 deprecated-1.2.14 docker-7.1.0 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.34.0 graphene-3.3 graphql-core-3.2.4 graphql-relay-3.2.0 greenlet-3.1.0 gunicorn-23.0.0 hydra-core-1.3.2 importlib-metadata-8.4.0 itsdangerous-2.2.0 markdown-3.7 mlflow-2.16.1 mlflow-skinny-2.16.1 omegaconf-2.3.0 opentelemetry-api-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 pandas-2.2.2 py4j-0.10.9.7 pyasn1-0.6.1 pyasn1-modules-0.4.1 pyspark-3.5.2 pyyaml-6.0.2 rsa-4.9 showcase-0.1.0 smmap-5.0.1 sqlalchemy-2.0.34 sqlparse-0.5.1 typing-extensions-4.12.2 tzdata-2024.1 wrapt-1.16.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "notebook_path = Path(dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get())\n",
    "whl_path = '/Workspace' + str(notebook_path.parent.parent.parent.parent.joinpath('artifacts/.internal/showcase-0.1.0-py3-none-any.whl'))\n",
    "%pip install $whl_path\n",
    "\n",
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d0cda5-2a01-4b19-8cd0-5ea3a1c2e609",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve 'ExperimentName' widget\nExperimentName: HousePricePrediction\nFailed to retrieve 'process_name' widget\nprocess_name: Model\nFailed to retrieve 'environment' widget\nenvironment: dev\nFailed to retrieve 'process_date' widget\nprocess_date: 2024-09-15\nFailed to retrieve 'ModelName' widget\nModelName: LinearRegression\nFailed to retrieve 'feature_list' widget\nfeature_list: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', 'YearBuilt', 'YearRemod/Add', 'TotalSF', 'PricePerSF', 'Qual_LivArea', 'GrLivAreaPoly', 'LotArea', 'FullBath', 'Age', 'LotFrontage', 'Fireplaces', 'Neighborhood_Index', 'HouseStyle_Index']\nFailed to retrieve 'mlflow_login' widget\nmlflow_login: false\n16332.677120747234\n"
     ]
    }
   ],
   "source": [
    "from showcase.HousePricePrediction.data_preprocessing.DataPreProcessingHousePricePredictor import (\n",
    "    DataPreProcessingHousePricePredictor,\n",
    ")\n",
    "from showcase.HousePricePrediction.model.HousePricePredictor import (\n",
    "    HousePricePredictor,\n",
    ")\n",
    "from showcase.utils.CentralArgs import CentralArgs\n",
    "from showcase.utils.constants import feature_set_one\n",
    "from showcase.utils.helpers import SparkHelpers\n",
    "from datetime import datetime as dt\n",
    "from pyspark.dbutils import DBUtils\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    task_config = {\n",
    "        \"HousePricePrediction\": {\n",
    "            \"DataPreProcessing\": DataPreProcessingHousePricePredictor,\n",
    "            \"Model\": HousePricePredictor,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Initialize variables with default values\n",
    "    ExperimentName = \"HousePricePrediction\"\n",
    "    process_name = \"Model\"\n",
    "    environment = \"dev\"\n",
    "    feature_list = feature_set_one\n",
    "    process_date = dt.strftime(dt.now(), \"%Y-%m-%d\")  # Default to current date\n",
    "    ModelName = \"LinearRegression\"\n",
    "    mlflow_login = \"false\"\n",
    "\n",
    "    spark = SparkHelpers.get_spark_session(\"entry-point-init\")\n",
    "\n",
    "    # Retrieve values from Databricks workflows\n",
    "    widget_names = [\n",
    "        \"ExperimentName\",\n",
    "        \"process_name\",\n",
    "        \"environment\",\n",
    "        \"process_date\",\n",
    "        \"ModelName\",\n",
    "        \"feature_list\",\n",
    "        \"mlflow_login\",\n",
    "    ]\n",
    "\n",
    "    for widget_name in widget_names:\n",
    "        try:\n",
    "            if widget_name == \"feature_list\":\n",
    "                globals()[widget_name] = globals()[\n",
    "                    DBUtils(spark).widgets.get(widget_name)\n",
    "                ]\n",
    "            else:\n",
    "                globals()[widget_name] = DBUtils(spark).widgets.get(widget_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to retrieve '{widget_name}' widget\")\n",
    "\n",
    "        print(f\"{widget_name}: {globals()[widget_name]}\")\n",
    "\n",
    "    spark = SparkHelpers.get_spark_session(ExperimentName)\n",
    "\n",
    "    task_config[ExperimentName][process_name](\n",
    "        CentralArgs(\n",
    "            spark=spark,\n",
    "            process_date=process_date,\n",
    "            ModelName=ModelName,\n",
    "            FeatureList=feature_list,\n",
    "            environment=environment,\n",
    "            mlflow_login=mlflow_login,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1691640550514641,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "main_notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
